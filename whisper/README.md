# Speech-to-Text(STT) 모델 비교 분석
OpenAI Whisper와 Facebook wav2vec2 모델의 성능 비교

## 실험 환경
- 도커 컨테이너 기반 실행 환경
- 한국어/영어 음성 인식 테스트
- 모델 버전:
  - Whisper: turbo
  - wav2vec2: wav2vec2-large-xlsr-korean (한국어), wav2vec2-base-960h (영어)

## 설치 및 실행 방법

### 환경 구성
```bash
docker compose up --build dev
```

### 모델 실행
```bash
cd src/wisper
python whisper_trans.py    # Whisper 모델 실행
python wav2vec2_trans.py   # wav2vec2 모델 실행
```

## 성능 평가 결과

### 한국어 음성 인식 테스트
#### Whisper 모델 결과
```
30대까지 체력이 변화하는 과정? 10살! 지치지 않는 아크리액터 체력 선물을 시켜주지 않으면 잠도 안 자는지라 아빠가 돌아주거나 태권도장 보내야 하라 초딩! 태권도장 보내는 이유가 진짜 이거라고 하던데? ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 10살부터 19살 언제 다 쓸까 싶은 고용량 배터리 겁나 일찍 등교해서 저녁 학원까지 마치고 돌아와도 놀지 못한 게 아니라? 컴퓨터를 느낌 이거 맞아 20살부터 24살 만짜리 보조배터리 고등학교 때 어떻게 연교실을 들었는지 의문이 드기 시작 이때 알바도 하고 학교도 하고 친구들이랑 술 마시고 날 밤 가고 막 차차 타고 가고 그리고 또 다음날 스케줄 다 소화하고 가능하지 않습니까? 어? 20대 중반부터 후반에 만짜리 보조배터리에서 에너자이지로 그냥 확 꺾이는데? ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 나이를 먹어보가면 슬슬 막차 시간까지 노는 게 힘들어짐 서른 살 이상 수온 건전지 슬슬 퇴근 후 술자리가 부담스러워짐 일찍 들어와서 자야함 중간중간 배터리에 방전될 수도 있어서 저의 충전해져요 너무 슬프다 마흔 살 이상? ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 이거는 전거나 잠깐 켜보는 거 아니야 이거?! 하하하하하
```

#### wav2vec2 모델 결과
```
삼십 들까주 츠로줄 변화는 광정 열울서 지지 자여 나타넷하 새력성물에서 퍼주지 니면 장두한자는지나 아빠가 더나서만 택검 자장 판 초인 백찬소 전 보면을 이후어 진짜 이거로 가 사에서 연악 사 현재 다세까시 큰 커의향경판이 전라직 행장에서 서영상방까지 마치고 살아나던 른심 현량 한참탄게 늘뤄어 승상에서 수물 천이 보점메이 포나프 어떻게 현경이 다라는지 의미 되별 걸과도 하고 확로더 하고 증구들며우술무실고 날범 저쳐고 사고 그루또 다음멸 수트줄더 소하고 변놀하습니까이십 대 진범부터 후부을 먼저이 보즈로 털리워서 에너조에 주며 사택들라일은 어어나며 세스 낙차시간 판이 던행게 힘전하지 퍼루사이 스물 전장지 승셜 세그의 세자리 가사람 사지 일직프라자야 중간중간 백터이 방전되스트스에서 지너우서리뉴전분 삼견 털일다
```

### 영어 음성 인식 테스트
테스트 영상: https://www.youtube.com/shorts/-06vZOkulZQ?feature=share

#### Whisper 모델 결과
```
Who knows how long I've loved you
You know I love you still
Will I wait a lonely lifetime
If you want me to, I will
```

#### wav2vec2 모델 결과
```
WHO KNOW WHHOSE HOW LONN AVE LOVE YOU YOU KNOW OW LO YOU STILL WELL I WAYME LIFE TIME IF YOU DATO I WILL IN
```

## 결론 및 제언

### 성능 비교
1. 정확도
   - Whisper가 두 언어 모두에서 월등히 우수한 성능 표현
   - 특히 문맥 이해와 자연스러운 문장 구성에서 큰 차이

2. 모델 특성
   - Whisper
     - 현재 테스트된 turbo 모델(1.5GB)도 높은 성능 발휘
     - large 모델 사용 시 더 높은 성능 기대 가능
   
   - wav2vec2
     - 기본 모델의 성능이 실용적 사용에 부적합
     - 한국어는 large 모델 사용 했음에도 성능이 낮음
     - 영어는 base 모델 사용했으나 기대 이하의 성능
     - 추가적인 fine-tuning 필요

### 권장사항
- 실제 서비스 적용 시 Whisper 모델 사용 권장
- 리소스 제약이 없다면 Whisper large 모델 검토 고려
- wav2vec2는 특수한 상황에서 fine-tuning 후 사용 검토

### 향후 연구 방향
- Whisper large 모델의 성능/리소스 트레이드오프 분석
- 특정 도메인에 대한 fine-tuning 효과 연구
- 실시간 처리 상황에서의 성능 비교

## 참고
- Repo 이름이 `whisper` 가 아니라 `wisper`로 된 이유, 오타임. 귀찮아서 수정 안 함.